# -*- coding: utf-8 -*-
"""app

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sYjfolQPRPFDPCfZBG5DCHcovhG65P67
"""

import streamlit as st
import cv2
import tensorflow as tf
import numpy as np
import pickle
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load the pre-trained tokenizer
tokenizer = pickle.load(open('myictoken.pk1', 'rb'))

# Load your deployed model here
model = tf.keras.models.load_model('myicmodel.h5')  # Load the model from model.h5

# Function to generate text from video frames
def generate_text_from_video(video_frames):
    captions = []

    # Loop through video frames and generate captions
    for frame in video_frames:
        # Preprocess the frame (you may need to adapt this part)
        # Example: frame = preprocess_frame(frame)

        # Tokenize the frame and generate a caption
        frame_sequence = tokenizer.texts_to_sequences([frame])[0]
        frame_sequence = pad_sequences([frame_sequence], maxlen=max_length, padding='post')
        caption = model.predict(frame_sequence, verbose=0)
        caption = tokenizer.sequences_to_texts([caption])[0]
        captions.append(caption)

    return captions

# Streamlit app
def main():
    st.title("Video Description Generator")

    # Upload video file
    uploaded_file = st.file_uploader("Upload a video (max 2MB)", type=["mp4"])

    if uploaded_file is not None:
        # Read the uploaded video
        video_file = cv2.VideoCapture(uploaded_file)

        frames = []
        while True:
            ret, frame = video_file.read()
            if not ret:
                break
            frames.append(frame)

        # Generate captions from frames
        st.text("Generating captions...")
        captions = generate_text_from_video(frames)

        # Display the captions
        st.header("Video Captions:")
        for caption in captions:
            st.write(caption)

if __name__ == "__main__":
    main()